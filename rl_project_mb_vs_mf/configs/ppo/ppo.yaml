policy: MlpPolicy
policy_kwargs:
  net_arch: [128, 128]
  activation_fn: torch.nn.Tanh

n_steps: 256
batch_size: 256
n_epochs: 10
gamma: 0.999
gae_lambda: 0.97
normalize_advantage: true
clip_range: 0.2
vf_coef: 0.5
clip_range_vf: null
max_grad_norm: 0.5
target_kl: 0.015

learning_rate: linear_schedule(3e-4)
optimizer_kwargs:
  eps: 1e-5

use_sde: true
sde_sample_freq: 4
ent_coef: 0.02
